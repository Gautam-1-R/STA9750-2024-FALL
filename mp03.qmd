---
title: "Mini Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?"
editor: visual
format:
  html: 
    code-link: true
---

------------------------------------------------------------------------

------------------------------------------------------------------------

## Introduction

::: {#01}
In this project, we are writing a *political fact-check*, that most iconic form of our current journalistic era. Specifically, we will investigate the claim that the [US Electoral College](https://en.wikipedia.org/wiki/United_States_Electoral_College) systematically biases election results away from the *vox populi*. As we dive in to the world of political data, we’ll also learn a bit more about the mechanics of US federal elections.

#### 
:::

In this project we will learn:

-   Integrate data from disparate governmental and academic sources

-   Learn to work with spatial data formats

-   Create *many* plots

-   Use spatial and animated visualizations to make your argument

## **Set-Up and Initial Exploration**

### **Data I: US House Election Votes from 1976 to 2022**

::: {.callout-note title="File Download" appearance="minimal"}
The [MIT Election Data Science Lab](https://electionlab.mit.edu/) collects votes from all biennial congressional races in all 50 states [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2). I downloaded the data form the website using the **"R Selenium"** package to simulate the chrome web browser and download the data with automation.
:::

<details>

<summary>**Loading all lib's once for full document**</summary>

Loading all the required libraries at once so that we can access them through full document.

```{r warning=FALSE, message=FALSE}
library(httr)
library(utils)
library(fs)
library(RSelenium)
library(purrr)
library(netstat)
library(wdman)
library(webdriver)
library(dplyr)
library(ggplot2)
library(readr)
library(shiny)
library(tidyr)
library(gt)
library(sf)
library(gganimate)
library(knitr)
library(kableExtra)
library(xml2)
library(downlit)
library(viridis)
library(leaflet)
```

</details>

<details>

<summary>**Defining helper functions (click to expand)**</summary>

Defining helper functions such as setting the directory where the downloads will be after the selenium session will download from the data set, safe_download function to effortlessly download file from any direct URL, defining URLs for the data and shape files etc.

```{r warning=FALSE, message=FALSE}
#Download Directory
get_downloads_dir <- function() {
  if (.Platform$OS.type == "windows") {
    return(file.path(Sys.getenv("USERPROFILE"), "Downloads"))
  } else {
    return(file.path(Sys.getenv("HOME"), "Downloads"))
  }
}

# Generic download function with error handling
safe_download <- function(url, destfile) {
  if (!file.exists(destfile)) {
    tryCatch(download.file(url, destfile, mode = "wb"),
             error = function(e) warning("Failed to download ", url))
  }
}

# Define dataset URLs and paths
dataset_urls <- list(
  "congressional_votes" = list(
    url = "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2",
    target_path = "data/votes/congressional_votes_1976_2022.csv"
  ),
  "presidential_votes" = list(
    url = "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX",
    target_path = "data/votes/presidential_votes_1976_2022.csv"
  )
)

# Define list of shapefile URLs for each year
shapefile_urls <- list(
  "1976" = "https://cdmaps.polisci.ucla.edu/shp/districts094.zip",
  "1978" = "https://cdmaps.polisci.ucla.edu/shp/districts095.zip",
  "1980" = "https://cdmaps.polisci.ucla.edu/shp/districts096.zip",
  "1982" = "https://cdmaps.polisci.ucla.edu/shp/districts097.zip",
  "1984" = "https://cdmaps.polisci.ucla.edu/shp/districts098.zip",
  "1986" = "https://cdmaps.polisci.ucla.edu/shp/districts099.zip",
  "1988" = "https://cdmaps.polisci.ucla.edu/shp/districts100.zip",
  "1990" = "https://cdmaps.polisci.ucla.edu/shp/districts101.zip",
  "1992" = "https://cdmaps.polisci.ucla.edu/shp/districts102.zip",
  "1994" = "https://cdmaps.polisci.ucla.edu/shp/districts103.zip",
  "1996" = "https://cdmaps.polisci.ucla.edu/shp/districts104.zip",
  "1998" = "https://cdmaps.polisci.ucla.edu/shp/districts105.zip",
  "2000" = "https://cdmaps.polisci.ucla.edu/shp/districts106.zip",
  "2002" = "https://cdmaps.polisci.ucla.edu/shp/districts107.zip",
  "2004" = "https://cdmaps.polisci.ucla.edu/shp/districts108.zip",
  "2006" = "https://cdmaps.polisci.ucla.edu/shp/districts109.zip",
  "2009" = "https://cdmaps.polisci.ucla.edu/shp/districts110.zip",
  "2010" = "https://cdmaps.polisci.ucla.edu/shp/districts111.zip",
  "2013" = "https://cdmaps.polisci.ucla.edu/shp/districts112.zip"
)


# Initialize RSelenium session
start_selenium <- function() {
  rD <- rsDriver(browser = "chrome", chromever = "latest", port = free_port())
  remDr <- rD$client
  list(rD = rD, remDr = remDr)
}

```

</details>

> Here we implemented the selenium function which will start a chrome(testing) session and simulate the downloads from loading URLs to filling and submitting the form. used the website logic from the buttons and JavaScript to get this done.

```{r warning=FALSE, message=FALSE}
# Download datasets with RSelenium form automation
download_dataset <- function(url, remDr) {
  remDr$navigate(url)
  Sys.sleep(5)  # Wait for page to load
  
# Trigger download form popup
  remDr$executeScript("var buttons = document.getElementsByClassName('ui-commandlink ui-widget btn-download'); if(buttons.length > 2) { buttons[2].click(); }")
  Sys.sleep(3)
  
# Fill out form fields
  remDr$findElement(using = "id", value = "datasetForm:guestbookuser_nameText")$sendKeysToElement(list("Mishra"))
  remDr$findElement(using = "id", value = "datasetForm:guestbookuser_email")$sendKeysToElement(list("mishra123@example.com"))
  remDr$findElement(using = "id", value = "datasetForm:guestbookuser_institution")$sendKeysToElement(list("UniMy"))
  remDr$findElement(using = "id", value = "datasetForm:guestbookuser_position")$sendKeysToElement(list("Student"))
  Sys.sleep(3)
  
# Accept and start download
  remDr$executeScript("var acceptButtons = document.getElementsByClassName('ui-button ui-widget ui-state-default ui-corner-all ui-button-text-only btn btn-default'); if(acceptButtons.length > 10) { acceptButtons[10].click(); }")
  Sys.sleep(7)  # Wait for download to complete
}


```

::: {.callout-note title="File Download" appearance="minimal"}
Till the time, we have defined the data set URLs and their path. Downloading code, Selenium session management and all form handling.
:::

<details>

<summary>**Selenium Server**</summary>

The main command to start the selenium server is defined here, after the command the downloaded files fill be created and copied into decided path.

```{r warning=FALSE, message=FALSE }


selenium <- start_selenium()
walk(dataset_urls, ~download_dataset(.x$url, selenium$remDr))
selenium$remDr$close()
selenium$rD$server$stop()

# Move downloaded files to the project directory
dir.create("data/votes", recursive = TRUE, showWarnings = FALSE)
downloads_dir <- get_downloads_dir()
file.copy(file.path(downloads_dir, "1976-2020-president.csv"), dataset_urls$presidential_votes$target_path, overwrite = FALSE)
file.copy(file.path(downloads_dir, "1976-2022-house.csv"), dataset_urls$congressional_votes$target_path, overwrite = TRUE)

```

</details>

### **Data II: Congressional Boundary Files 1976 to 2012**

Jeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis have created *shapefiles* for all US congressional districts from 1789 to 2012; they generously make these available [here](https://cdmaps.polisci.ucla.edu/).

::: {.callout-note title="Task 1: Download Congressional Shapefiles 1976-2012" appearance="minimal"}
Downloading congressional shapefiles from Lewis *et al.* for all US Congresses\[\^5\] from 1976 to 2012.

1)  Fully automated Code

2)  Systematic and interpretative naming conventions used.

3)  Added a check to prevent multiple downloads
:::

<details>

<summary>**Code to download Shapefiles**</summary>

Downloading the **Congressional Boundary Files** which we are going to use to make chloropleth maps.

```{r warning=FALSE, message=FALSE}

# Function to download and extract .shp files with error handling
download_shapefile <- function(year, url) {
  zip_path <- paste0("data/shapefiles/congressional_shapefile_", year, ".zip")
  safe_download(url, zip_path)
  
}

# Download and extract shapefiles for each year
walk2(names(shapefile_urls), shapefile_urls, download_shapefile)

message("All datasets and shapefiles downloaded and organized.")

```

</details>

### **Data III: Congressional Boundary Files 2014 to Present**

To get district boundaries for more recent congressional elections, we turned to the US Census Bureau. Reviewed and downloaded the US Census Bureau shape files [online](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). from the `FTP Archive` link near the bottom of the page.

::: {.callout-note title="Task 2: Download Congressional Shapefiles 2014-2022" appearance="minimal"}
Downloading congressional shape files from the US Census Bureau for all US Congresses from 2014 to 2022.

1)  Fully automated (no "hand-downloading");
2)  Systematic and interpretative naming convention
3)  Only download files as needed out of courtesy for the data provider's web sever.
:::

<details>

<summary>**Downloading Congressional Boundary Files 2014 to 2022**</summary>

```{r warning=FALSE, message=FALSE}

# Define the download directory
get_download_dir <- function() {
  dir <- "data/shapefiles/census_congressional_districts"
  if (!dir.exists(dir)) dir_create(dir)
  return(dir)
}

# Define years and session numbers (2014-2022 covers 113th to 117th congressional sessions)
years_sessions <- list(
  "2014" = "114", "2015" = "114", "2016" = "115",
  "2017" = "115", "2018" = "116", "2019" = "116",
  "2020" = "116", "2021" = "116", "2022" = "116"
)

# Define the base URL structure for Census Bureau shape files for congressional districts
base_url <- "https://www2.census.gov/geo/tiger/TIGER"

# Function to download specific shapefiles based on user input
download_specific_shapefiles <- function(shapefile_list) {
  download_dir <- get_download_dir()
  
  # Iterate over each specified shapefile in the list
  for (item in shapefile_list) {
    year <- as.character(item$year)
    state_code <- item$state_code
    session <- ifelse(!is.null(item$session), item$session, years_sessions[[year]])
    
    # Determine file name based on state or national download
    if (1 == 1) {
      file_name <- paste0("tl_", year, "_us_cd", session, ".zip")
    } 
    
    # Construct the download URL
    url <- paste0(base_url, year, "/CD/", file_name)
    destfile <- file.path(download_dir, file_name)
    
    # Check if the file already exists to avoid redundant downloads
    if (!file_exists(destfile)) {
      tryCatch({
        message("Downloading: ", url)
        download.file(url, destfile, method = 'curl', mode = "wb")
        message("Downloaded successfully: ", file_name)
      }, error = function(e) {
        message("Failed to download ", url, ": ", e$message)
      })
    } else {
      message("File already exists: ", file_name)
    }
  }
}

# List of shapefiles to download with specific years and states
shapefiles_to_download <- list(
  list(year = 2014, state_code = "us"),
  list(year = 2016, state_code = "us"),
  list(year = 2020, state_code = "us"),
  list(year = 2022, state_code = "us")
)

# Call the function with the specific list of shapefiles
download_specific_shapefiles(shapefiles_to_download)
```

</details>

### **Initial Exploration of Vote Count Data**

::: {.callout-note title="Task 3: Exploration of Vote Count Data" appearance="minimal"}
Answer the following using the vote count data files from the MIT Election Data Science Lab.

1.  Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?

2.  New York State has a unique "fusion" voting system where one candidate can appear on multiple "lines" on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS' 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).

    Are there any elections in our data where the election would have had a different outcome if the "fusion" system was not used and candidates only received the votes their received from their "major party line" (Democrat or Republican) and not their total number of votes across all lines?

3.  Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?

    Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?
:::

> 1.  Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?
>
>     We will calculate the gained and lost seats in states by using the Congressional data we downloaded in the first step. And then plot a bar graph.

<details>

<summary>**Calculation of** **Top Gains and Losses**</summary>

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Path
congressional_data_path <- "data/votes/congressional_votes_1976_2022.csv"

# Load the congressional vote data with error handling
congressional_data <- tryCatch({
  read_csv(congressional_data_path) %>%
    select(year, state, district) %>%
    distinct()
}, error = function(e) {
  stop("Error loading data: ", e$message)
})

# Unique districts / State
districts <- congressional_data %>%
  group_by(year, state) %>%
  summarize(districts_count = n_distinct(district), .groups = 'drop')

# Calculating changes between 1976 and 2022
seat_changes_1976_2022 <- districts %>%
  filter(year %in% c(1976, 2022)) %>%
  pivot_wider(names_from = year, values_from = districts_count, names_prefix = "year_") %>%
  mutate(seat_change = year_2022 - year_1976)

# Separate the states with the most gains and losses
top_gains <- seat_changes_1976_2022 %>% arrange(desc(seat_change)) %>% head(5)
top_losses <- seat_changes_1976_2022 %>% arrange(seat_change) %>% head(5)


```

</details>

#### 3.1: Plotting the Top Gains and Losses

```{r}
# Plot for seat gains
gain_plot <- ggplot(top_gains, aes(x = reorder(state, seat_change), y = seat_change, fill = seat_change)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 5 Most Gained Seats ",
       x = "States",
       y = "Seats Gained") +
  scale_fill_gradient(low = "yellow", high = "orange") +
  theme_minimal()

# Plot for seat losses
lost_plot <- ggplot(top_losses, aes(x = reorder(state, seat_change), y = seat_change, fill = -seat_change)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 5 Most Lost Seats",
       x = "States",
       y = "Seats Lost") +
  scale_fill_gradient(low = "pink", high = "violet") +
  theme_classic()


```

::: {style="display: flex; padding:20px; gap:10px;"}
```{r}
gain_plot 


```

```{r}
lost_plot
```
:::

This Bar chart indicates where seats were gained ans we can see in the yellow-orange chart that Texas was leading the data followed by Florida and California.

Similarly in the lost plot New York lost most number of seats.

<details>

<summary>**Code for Tabulating the Top Gains and Losses**</summary>

```{r}

# Create the gains table
gains_table <- top_gains %>%
  gt() %>%
  tab_header(
    title = "Top 5 States with Most District Gains (1976-2022)"
  ) %>%
  cols_label(
    state = "State",
    year_1976 = "Districts in 1976",
    year_2022 = "Districts in 2022",
    seat_change = "Change in Seats"
  ) %>%
  fmt_number(
    columns = starts_with("year_"),
    decimals = 0
  ) %>%
  fmt_number(
    columns = seat_change,
    decimals = 0,
    pattern = "+{x}" # Shows "+" for positive values
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold", color = "green")
    ),
    locations = cells_body(columns = seat_change, rows = seat_change > 0)
  )

# Create the losses table
losses_table <- top_losses %>%
  gt() %>%
  tab_header(
    title = "Top 5 States with Most District Losses (1976-2022)"
  ) %>%
  cols_label(
    state = "State",
    year_1976 = "Districts in 1976",
    year_2022 = "Districts in 2022",
    seat_change = "Change in Seats"
  ) %>%
  fmt_number(
    columns = starts_with("year_"),
    decimals = 0
  ) %>%
  fmt_number(
    columns = seat_change,
    decimals = 0,
    pattern = "{x}" # No "+" sign for negative values
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold", color = "red")
    ), 
    locations = cells_body(columns = seat_change, rows = seat_change < 0)
  )


```

</details>

The table represents the top 5 most district gains and losses in the states.

::: {style="display: flex; padding:20px; gap:25px;"}
```{r echo=TRUE, message=FALSE, warning=FALSE}
gains_table

```

```{r echo=TRUE, message=FALSE, warning=FALSE}
losses_table
```
:::

#### 3.2: New York Fusion System analysis

> 2.  New York State has a unique "fusion" voting system where one candidate can appear on multiple "lines" on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS' 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).
>
>     Are there any elections in our data where the election would have had a different outcome if the "fusion" system was not used and candidates only received the votes their received from their "major party line" (Democrat or Republican) and not their total number of votes across all lines?

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Load congressional vote data
congressional_votes <- read_csv("data/votes/congressional_votes_1976_2022.csv")

# Filter for New York elections with fusion voting
ny_votes <- congressional_votes %>%
  filter(state == "NEW YORK") %>%
  filter(!is.na(fusion_ticket))  # Focus on fusion voting cases

# Check how many records are in ny_votes
n_ny_votes <- nrow(ny_votes)

if (n_ny_votes == 0) {
  flog.warn("No records found for New York with fusion voting.")
} else {
  fusion_analysis <- ny_votes %>%
    mutate(is_major_party = party %in% c("DEMOCRAT", "REPUBLICAN")) %>%
    group_by(year, district, candidate) %>%
    summarise(
      total_votes_all_lines = sum(candidatevotes),
      major_party_votes = sum(candidatevotes[is_major_party]),
      .groups = "drop"
    )
  
  # Determining winners with fusion voting
  winners_fusion <- fusion_analysis %>%
    group_by(year, district) %>%
    filter(total_votes_all_lines == max(total_votes_all_lines)) %>%
    select(year, district, candidate, total_votes_all_lines) %>%
    rename(fusion_winner = candidate, fusion_votes = total_votes_all_lines)
  
  # Without fusion voting
  winners_nonfusion <- fusion_analysis %>%
    group_by(year, district) %>%
    filter(major_party_votes == max(major_party_votes)) %>%
    select(year, district, candidate, major_party_votes) %>%
    rename(nonfusion_winner = candidate, nonfusion_votes = major_party_votes)
  
  # Comparison of fusion vs non-fusion winners
  election_outcomes <- winners_fusion %>%
    inner_join(winners_nonfusion, by = c("year", "district")) %>%
    filter(fusion_winner != nonfusion_winner)
  
}

```

<details>

<summary>**Tabulation of data**</summary>

```{r}

# Select only the top 8 rows
top_8_outcomes <- head(election_outcomes, 5)
 

# Render a table with gt for a styled output
table_t5o <- top_8_outcomes %>%
  gt() %>%
  tab_header(
    title = "Fusion vs Non-Fusion Election Outcomes - Top 8 Entries"
  ) %>%
  cols_label(
    year = "Year",
    district = "District",
    fusion_winner = "Fusion Winner",
    fusion_votes = "Fusion Votes",
    nonfusion_winner = "Non-Fusion Winner",
    nonfusion_votes = "Non-Fusion Votes"
  ) %>%
  fmt_number(
    columns = c(fusion_votes, nonfusion_votes),
    decimals = 0
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", color = "blue"),
    locations = cells_body(columns = fusion_winner)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", color = "red"),
    locations = cells_body(columns = nonfusion_winner)
  )



```

</details>

Upon analyzing the data we found out that there is really a factor of fusion voting system that if there was no fusion there would be another winner which is clearly reprasented in the table below, which shows various names such as EDWARD-JOSEPH, JOHN-LESTER etc. where the results could be different if fusion was not the factor.

```{r}
table_t5o
```

#### 3.3: Analysis of various trends

> 3.  Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?
>
>     Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?

<br>

##### **I: Percentage Difference B/W Presidential and Congressional Votes**

```{r warning=FALSE, message=FALSE}

# Load data
president_data <- read.csv("data/votes/presidential_votes_1976_2022.csv")
house_data <-  read_csv("data/votes/congressional_votes_1976_2022.csv")

# Summarize presidential votes (1976-2012)
presidential_votes <- president_data %>%
  filter(office == "US PRESIDENT", year >= 1976, year <= 2012) %>%
  group_by(year) %>%
  summarise(total_president_votes = sum(candidatevotes), .groups = "drop")

# Summarize congressional votes (1976-2012)
congressional_votes <- house_data %>%
  filter(office == "US HOUSE", year >= 1976, year <= 2012) %>%
  group_by(year) %>%
  summarise(total_congress_votes = sum(candidatevotes), .groups = "drop")

# Combine the two datasets
vote_comparison <- presidential_votes %>%
  left_join(congressional_votes, by = "year")

# Calculate percentage difference
vote_comparison <- vote_comparison %>%
  mutate(vote_percentage_difference = 
           (total_president_votes - total_congress_votes) / total_congress_votes)

```

With this Percentage difference comparison bar plot and the table we have figured out, that presidential votes are ahead of the congressional votes with certain percentage and the amount is significant.

```{r }
# Plot percentage difference
ggplot(vote_comparison, aes(x = year, y = vote_percentage_difference)) +
  geom_bar(stat = "identity", fill = "violet", color = "violet", width = 1.5) +
  labs(
    title = "Percentage Difference B/W Presidential and Congressional Votes (1976 - 2012)",
    x = "Year",
    y = "Vote Percentage Difference (%)"
  ) +
  theme_minimal()
```

```{r}
# Display vote_comparison table
vote_comparison %>%
  mutate(
    vote_percentage_difference = scales::percent(vote_percentage_difference, accuracy = 0.1)
  ) %>%
  head(8) %>%  # Show only the top 8 rows
  kable(
    caption = "Comparison of Presidential and Congressional Votes (1976-2012)",
    col.names = c("Year", "Total Presidential Votes", "Total Congressional Votes", "Vote Percentage Difference")
  ) %>%
  kable_styling("striped", full_width = F)

```

<br>

##### **II: State-wise Comparison of Presidential vs Congressional Votes (1976-2012)**

```{r warning=FALSE, message=FALSE}
# Load data
president_data <- read.csv("data/votes/presidential_votes_1976_2022.csv")
house_data <- read_csv("data/votes/congressional_votes_1976_2022.csv")

# Aggregate votes by state for presidential and congressional candidates (1976-2012)
congressional_state_votes <- house_data %>%
  filter(office == "US HOUSE", year >= 1976, year <= 2012) %>%
  group_by(year, state) %>%
  summarise(congress_votes = sum(candidatevotes), .groups = "drop")

presidential_state_votes <- president_data %>%
  filter(office == "US PRESIDENT", year >= 1976, year <= 2012) %>%
  group_by(year, state) %>%
  summarise(president_votes = sum(candidatevotes), .groups = "drop")

# Combine the datasets into a comparison table
state_vote_comparison <- presidential_state_votes %>%
  left_join(congressional_state_votes, by = c("state", "year"))

# Calculate percentage difference (optional, if desired)
state_vote_comparison <- state_vote_comparison %>%
  mutate(vote_percentage_difference = 
           (president_votes - congress_votes) / congress_votes * 100)

```

```{r}
# Show top 10 entries of the table
state_vote_comparison %>%
  arrange(desc(year)) %>%
  head(10) %>%
  kable(col.names = c("Year", "State", "Presidential Votes", "Congressional Votes", "Percentage Difference"),
        caption = "State-wise Comparison of Presidential vs Congressional Votes (1976-2012)")

```

<br>

##### **III: Party-wise Comparison of Votes for Presidential and Congressional Candidates**

```{r}
# Aggregate votes by party for presidential and congressional candidates
congressional_party_votes <- house_data %>%
  filter(office == "US HOUSE", year >= 1976, year <= 2012) %>%
  group_by(year, party) %>%
  summarise(congress_votes = sum(candidatevotes), .groups = "drop")

pres_votes <- president_data %>%
  filter(office == "US PRESIDENT", year >= 1976, year <= 2012) %>%
  group_by(year, party_simplified) %>%
  summarise(president_votes = sum(candidatevotes), .groups = "drop") %>%
  rename(party = party_simplified)

# Combine the data sets
pres_vote_comparison <- pres_votes %>%
  left_join(congressional_party_votes, by = c("party", "year"))

# Reshape data for plotting
vote_long <- pres_vote_comparison %>%
  pivot_longer(cols = c(president_votes, congress_votes), 
               names_to = "vote_type", 
               values_to = "votes")

# Plotting stacked area graph by party
ggplot(vote_long, aes(x = year, y = votes, fill = party)) +
  geom_area(stat="identity", position="stack") +
  facet_wrap(~ vote_type) +
  labs(title = "Votes for Presidential vs. Congressional Candidates (1976 - 2012)",
       x = "Year",
       y = "Votes",
       fill = "Party", caption = "Data presented") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "top")
```

```{r}
# Create the table to show a comparison between presidential and congressional votes
comparison_table <- pres_vote_comparison %>%
  select(year, party, president_votes, congress_votes) %>%
  arrange(desc(year))

# Display the top 10 rows in a nicely formatted table
comparison_table %>%
  head(10) %>%
  kable(col.names = c("Year", "Party", "Presidential Votes", "Congressional Votes"),
        caption = "Party-wise Comparison of Votes for Presidential and Congressional Candidates (1976-2012)")

```

::: {.callout-note title="Task 3: Report on analysis" appearance="simple"}
Upon analyzing the data trends in task 3, we found out that Presidential candidates often run ahead of the congressional candidates. Thought this percentage difference might be smaller but it make and big impact as it was shown in the report.

In the state wise comparison the presidential votes were significantly higher than the congressional votes. For party-wise comparison the stats were also similar as above.
:::

### **Importing and Plotting Shape File Data**

The shape files are distributed in `zip` archives, with several files. We only need the `shp` file within each archive. In this section, we’ll be extracting the `shp` file, reading it, and using it to create a plot. The key library we need is the `sf` (“simple features”) library. It provides the [`read_sf()`](https://r-spatial.github.io/sf/reference/st_read.html) function which we can use to read it into `R.`

::: {.callout-note title="Task 4: Automate Zip File Extraction" appearance="simple" icon="false"}
A *function* load_the_shapefiles`()` which takes the folder path of downloaded files, pulls out the `.shp` file contained there in, and reads it into `R` using `read_sf()`.
:::

```{r}


# Global variable to store loaded shapefiles
the_shapefiles <- list()

# Function to read UCLA shapefiles into R with individual file checks
load_the_shapefiles <- function(folder_path) {
  
  # Get the list of zip files in the folder
  zip_files <- list.files(folder_path, pattern = "\\.zip$", full.names = TRUE)
  
  for (zip_archive in zip_files) {
    temp_directory <- tempdir()
    unzip(zip_archive, exdir = temp_directory)
    
    # List shapefiles within the extracted directory
    shapefile_paths <- list.files(temp_directory, pattern = "\\.shp$", full.names = TRUE, recursive = TRUE)
    
    for (shape_path in shapefile_paths) {
      shapefile_name <- basename(shape_path)
      
      # Check if this shapefile has already been loaded
      if (is.null(the_shapefiles[[shapefile_name]])) {
        tryCatch({
          # Read and store the shapefile if not already loaded
          spatial_data <- sf::st_read(shape_path)
          the_shapefiles[[shapefile_name]] <- spatial_data
          
        }, error = function(error_msg) {
          message(paste("Error reading file:", shape_path, ":", error_msg$message))
        })
      } 
    }
  }
  
  return(the_shapefiles)
}

```

<details>

<summary>**Execution of the code**</summary>

```{r}

# Define the shapefile directory
the_shapefile_folder <- "data/shapefiles"

# Read the downloaded UCLA shapefiles into R
the_shapefiles <- load_the_shapefiles(the_shapefile_folder)

```

</details>

### **Chloropleth Visualization of the 2000 Presidential Election Electoral College Results**

::: {.callout-note title="Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results" appearance="minimal"}
Using the data you downloaded earlier, create a *chloropleth* visualization of the electoral college results for the 2000 presidential election (Bush *vs.* Gore), coloring each state by the party that won the most votes in that state.
:::

<details>

<summary>**Data Loading**</summary>

```{r}
# Load the election data (assuming it is in CSV format)
election_data <- read.csv("data/votes/presidential_votes_1976_2022.csv")

# Filter data for the 2000 presidential election
election_2000 <- election_data %>%
  filter(year == 2000, office == "US PRESIDENT")

# Determine the winning party per state
state_winners <- election_2000 %>%
  group_by(state, state_po) %>%
  summarise(winning_party = party_simplified[which.max(candidatevotes)]) %>%
  ungroup()

# Load the US shapefile
us_states <- the_shapefiles[["districts106.shp"]]

# Optional: Filter out territories if needed
us_states <- us_states %>%
  filter(!STATENAME %in% c("Alaska", "Hawaii", "Puerto Rico"))
state_abbreviations <- data.frame(
  STATENAME = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware",
                "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky",
                "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi",
                "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico",
                "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania",
                "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont",
                "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"),
  state_po = c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "HI", "ID", "IL", "IN", "IA", "KS",
               "KY", "LA", "ME", "MD", "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY",
               "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV",
               "WI", "WY")
)
```

</details>

```{r}
# Join `us_states` with `state_abbreviations` to add abbreviations
us_states <- us_states %>%
  left_join(state_abbreviations, by = "STATENAME")

# Join with `state_winners` to add winning party information
us_map_data <- us_states %>%
  left_join(state_winners, by = "state_po")

# Define colors for each party
party_colors <- c(
  "REPUBLICAN" = "red",
  "DEMOCRAT" = "blue",
  "OTHER" = "gray"
)

# Reproject to Albers Equal Area (or another suitable CRS)
us_map_data <- st_transform(us_map_data, crs = 5070)  # EPSG code 5070 is a common Albers projection for the U.S.

# Create the choropleth map
ggplot(data = us_map_data) +
  geom_sf(aes(fill = winning_party), color = "white") +
  scale_fill_manual(values = party_colors, name = "Winning Party") +
  labs(title = "2000 U.S. Presidential Election Results by State",
       subtitle = "States colored by the party with the most votes") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

### **Advanced Chloropleth Visualization**

::: {.callout-note title="Task 6: Advanced Chloropleth Visualization of Electoral College Results" appearance="minimal"}
Modify your previous code to make either an *animated* version showing election results over time.
:::

<details>

<summary>**Downloading the shapefile**</summary>

```{r}
safe_download <- function(url, destfile) {
  if (!file.exists(destfile)) {
    tryCatch(download.file(url, destfile, mode = "wb"),
             error = function(e) warning("Failed to download ", url))
  }
}

safe_download("https://drive.usercontent.google.com/uc?id=1tkRPPYIKpOICUdO1eJfrHAnHhF7RSorG&export=download", "cb_2018_us_cd116_5m.zip")


##-
td <- tempdir(); 
zip_contents <- unzip("cb_2018_us_cd116_5m.zip", 
                      exdir = td)
    
fname_shp <- zip_contents[grepl("shp$", zip_contents)]
fname_dbf <- zip_contents[grepl("dbf$", zip_contents)]
fname_shx <- zip_contents[grepl("shx$", zip_contents)]


# Load the shapefile
shapefile_path <- "cb_2018_us_cd116_5m.shp"
us_sf <- read_sf(fname_shp)
us_sf

```

</details>

```{r}

# Create the repeated data for animation
us_sf_repeats <- bind_rows(
    us_sf |> mutate(value = rnorm(441), frame = 1), 
    us_sf |> mutate(value = rnorm(441), frame = 2), 
    us_sf |> mutate(value = rnorm(441), frame = 3), 
    us_sf |> mutate(value = rnorm(441), frame = 4), 
    us_sf |> mutate(value = rnorm(441), frame = 5)
)
bbox <- st_bbox(us_sf)
```

### Animation Plot

```{r}
# Create the plot with adjusted scaling and color
 ggplot(us_sf_repeats, 
                         aes(geometry = geometry, fill = value)) + 
    geom_sf() + 
    transition_time(frame) + 
    scale_fill_viridis_c() +  
    theme_minimal() +  
    labs(title = "") + 
    theme(legend.position = "bottom") +
    coord_sf(xlim = c(bbox["xmin"], bbox["xmax"] -bbox["xmax"]/1), 
             ylim = c(bbox["ymin"] - bbox["ymin"], bbox["ymax"] ), 
             expand = FALSE) 
```

### **Interactive Map**

```{r warning=FALSE, message=FALSE}
# Create a popup text combining state and district information
us_sf <- us_sf %>% 
  mutate(popup_info = paste("State FIPS:", STATEFP, "<br>",
                            "District:", CD116FP, "<br>",
                            "GEOID:", GEOID))

# Create the leaflet map with polygons and popup info
leaflet(data = us_sf) %>%
  addTiles() %>%
  setView(lng = -98.583, lat = 39.833, zoom = 4) %>% 
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", us_sf$ALAND)(us_sf$ALAND),
    weight = 1,
    opacity = 1,
    color = "white",
    fillOpacity = 0.7,

    popup = ~popup_info  
  ) %>%
  addLegend(
    pal = colorQuantile("YlOrRd", us_sf$ALAND), 
    values = us_sf$ALAND,
    title = "Area (sq meters)",
    position = "bottomright"
  )
```

### **Evaluating Fairness of ECV Allocation Schemes**

::: {.callout-note title="Task 7: Evaluating Fairness of ECV Allocation Schemes" appearance="minimal"}
Write a fact check evaluating the fairness of the different ECV electoral allocation schemes.

To do so, you should first determine which allocation scheme you consider "fairest". You should then see which schemes give different results, if they ever do. To make your fact check more compelling, select one election where the ECV scheme had the largest impact--if one exists--and explain how the results would have been different under a different ECV scheme.

As you perform your analysis, you may assume that the District of Columbia has three ECVs, which are allocated to the Democratic candidate under all schemes except possibly national popular vote.\[\^8\]
:::

Going through the historical voting data and assign each state's ECVs according to various strategies:

1.  State-Wide Winner-Take-All
2.  District-Wide Winner-Take-All + State-Wide "At Large" Votes
3.  State-Wide Proportional
4.  National Proportional

<details>

<summary>**Loading Data Files**</summary>

```{r message=FALSE, warning=FALSE}

# Load the datasets
# Replace file paths with the actual paths to your data files
presidential_data <- read_csv("data/votes/presidential_votes_1976_2022.csv")
congressional_data <- read_csv("data/votes/congressional_votes_1976_2022.csv")
ecv_data <- read_csv("https://drive.usercontent.google.com/uc?id=1cKsJs0N37xseWLYVhqdpWGFqoiq9Q7HS&export=download")

# Standardize and Clean Data
# 1. Standardize state names to uppercase for consistency across datasets.
# 2. Remove rows with missing necessary values in each dataset.
presidential_data <- presidential_data %>%
  mutate(state = toupper(state)) %>%
  filter(!is.na(candidate), !is.na(candidatevotes), !is.na(totalvotes))

congressional_data <- congressional_data %>%
  mutate(state = toupper(state)) %>%
  filter(!is.na(candidate), !is.na(candidatevotes), !is.na(totalvotes), !is.na(district))

ecv_data <- ecv_data %>%
  rename(year = Year, state = State, ecv = Votes) %>%
  mutate(state = toupper(state)) %>%
  filter(!is.na(ecv))
```

</details>

<details>

<summary>**ECV Allocation Function**</summary>

```{r  message=FALSE, warning=FALSE}
# Define ECV Allocation Function
# This function takes in presidential and congressional vote data, ECV data, 
# and an allocation scheme to calculate Electoral College Votes (ECVs).
allocate_ecvs <- function(pres_data, cong_data, ecv_data, scheme) {
  tryCatch({
    if (scheme == "state_winner_take_all") {
      # State-Winner-Take-All Allocation
      # Identify the state-level candidate with the most votes.
      state_winner <- pres_data %>%
        group_by(year, state) %>%
        filter(candidatevotes == max(candidatevotes)) %>%
        slice(1) %>%
        select(year, state, candidate) %>%
        rename(state_winner = candidate)
      
      # Allocate ECVs to the winning candidate for each state.
      data <- pres_data %>%
        left_join(state_winner, by = c("year", "state")) %>%
        left_join(ecv_data, by = c("year", "state")) %>%
        mutate(ecv_allocation = ifelse(candidate == state_winner, ecv, 0)) %>%
        filter(!is.na(ecv_allocation))
      
    } else if (scheme == "district_winner_take_all") {
      # District-Winner-Take-All Allocation
      # Identify district-level winning candidates.
      district_winner <- cong_data %>%
        group_by(year, state, district) %>%
        filter(candidatevotes == max(candidatevotes)) %>%
        slice(1) %>%
        select(year, state, district, candidate) %>%
        rename(district_winner = candidate)
      
      # Allocate ECVs based on district-level winners.
      data <- cong_data %>%
        left_join(district_winner, by = c("year", "state", "district")) %>%
        left_join(ecv_data, by = c("year", "state")) %>%
        mutate(ecv_allocation = ifelse(candidate == district_winner, ecv / n_distinct(district), 0)) %>%
        filter(!is.na(ecv_allocation))
      
    } else if (scheme == "state_proportional") {
      # State Proportional Allocation
      # Calculate each candidate's share of the state votes and allocate ECV proportionally.
      data <- pres_data %>%
        left_join(ecv_data, by = c("year", "state")) %>%
        group_by(year, state) %>%
        mutate(state_vote_share = candidatevotes / totalvotes,
               ecv_allocation = round(state_vote_share * ecv, 0)) %>%
        filter(!is.na(ecv_allocation))
      
    } else if (scheme == "national_proportional") {
      # National Proportional Allocation
      # Calculate each candidate's share of national votes and allocate ECVs proportionally.
      national_totals <- pres_data %>%
        group_by(year, candidate) %>%
        summarize(total_national_votes = sum(candidatevotes), .groups = 'drop') %>%
        mutate(national_vote_share = total_national_votes / sum(total_national_votes))
      
      total_ecv <- sum(ecv_data$ecv, na.rm = TRUE)
      
      data <- pres_data %>%
        left_join(national_totals, by = c("year", "candidate")) %>%
        mutate(ecv_allocation = round(national_vote_share * total_ecv, 0)) %>%
        filter(!is.na(ecv_allocation))
    }
    
    # Summarize total ECVs allocated per candidate by year
    ecv_summary <- data %>%
      group_by(year, candidate) %>%
      summarize(total_ecvs = sum(ecv_allocation, na.rm = TRUE), .groups = 'drop')
    
    return(ecv_summary)
    
  }, error = function(e) {
    message("Error in allocate_ecvs function:")
    print(e)
  })
}

```

</details>

```{r}
# Apply each allocation scheme and store results for comparison.
state_wta_results <- allocate_ecvs(presidential_data, congressional_data, ecv_data, "state_winner_take_all")
district_wta_results <- allocate_ecvs(presidential_data, congressional_data, ecv_data, "district_winner_take_all")
state_proportional_results <- allocate_ecvs(presidential_data, congressional_data, ecv_data, "state_proportional")
national_proportional_results <- allocate_ecvs(presidential_data, congressional_data, ecv_data, "national_proportional")

# Combine results for comparison
compare_results <- state_wta_results %>%
  rename(state_wta_ecv = total_ecvs) %>%
  left_join(district_wta_results, by = c("year", "candidate"), suffix = c("", "_district_wta")) %>%
  left_join(state_proportional_results, by = c("year", "candidate"), suffix = c("", "_state_proportional")) %>%
  left_join(national_proportional_results, by = c("year", "candidate"), suffix = c("", "_national_proportional")) %>%
  mutate(difference_state_vs_national = abs(state_wta_ecv - total_ecvs_national_proportional),
         difference_state_vs_proportional = abs(state_wta_ecv - total_ecvs_state_proportional))


# Clean up NA values in the results
compare_results_clean <- compare_results %>%
  mutate(across(starts_with("total_ecvs"), ~ replace_na(., 0)))

# Identify elections where allocation schemes changed the winner
winner_analysis <- compare_results_clean %>%
  group_by(year) %>%
  summarise(
    actual_winner = candidate[which.max(state_wta_ecv)],
    proportional_winner = candidate[which.max(total_ecvs_state_proportional)],
    national_winner = candidate[which.max(total_ecvs_national_proportional)],
    state_vs_proportional_difference = max(abs(state_wta_ecv - total_ecvs_state_proportional), na.rm = TRUE),
    state_vs_national_difference = max(abs(state_wta_ecv - total_ecvs_national_proportional), na.rm = TRUE)
  ) %>%
  filter(actual_winner != proportional_winner | actual_winner != national_winner)
```

```{r}

# Display table
library(knitr)
kable(winner_analysis, 
      col.names = c("Year", 
                    "Actual Winner (State WTA)", 
                    "Proportional Winner", 
                    "National Winner", 
                    "State vs Proportional ECV Difference", 
                    "State vs National ECV Difference"),
      caption = "Elections Where ECV Allocation Scheme Could Change Outcome")

```

::: {.callout-note title="Task 7Report" appearance="minimal"}
To evaluate the fairness of different Electoral College Vote (ECV) allocation schemes, this analysis compares outcomes under several models: State-Wide Winner-Take-All (the current method), District-Wide Winner-Take-All + State-Wide "At Large" Votes, State-Wide Proportional, and National Proportional allocation. By applying these methods to historical election data, we identify cases where different allocation rules could have changed the winner. For example, in the 2000 election, Al Gore would have won under a State-Wide Proportional scheme, while in 2016, Hillary Clinton would have emerged victorious with either Proportional scheme (state or national), rather than the actual outcome. These findings suggest that alternative schemes could lead to more representative results, as they potentially reduce the disparity between popular votes and ECVs awarded. This analysis highlights the substantial impact that different ECV allocations can have on outcomes, offering a basis for further exploration of which scheme may align best with democratic fairness principles.
:::
